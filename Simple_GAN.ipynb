{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWFFouVOkcC84NXKM0t5k8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filsto/GAN/blob/main/Simple_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a simple Generative Adversarial Network using Tensorflow"
      ],
      "metadata": {
        "id": "jbgsC7ONSEMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n96w0qTtSCsP"
      },
      "outputs": [],
      "source": [
        "# Generating training data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_y(x):\n",
        "  return 10+x*x\n",
        "\n",
        "def sample_data(n=10000, scale=100):\n",
        "  data=[]\n",
        "\n",
        "  x = scale*(np.random.random_sample((n,))-0.5)\n",
        "\n",
        "  for i in range (n):\n",
        "    yi = get_y(x[i])\n",
        "    data.append(x[i], yi)\n",
        "\n",
        "  return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator and discriminator networks implementation\n",
        "\n",
        "def generator (Z, hsize=[16,16], reuse=False):\n",
        "  with tf.variable_scope(\"GAN/Generator\", reuse=reuse):\n",
        "    h1 = tf.layers.Dense(Z, hsize[0], activation=tf.nn.leaky_relu)\n",
        "    h2 = tf.layers.Dense(h1, hsize[1], activation=tf.nn.leaky_relu)\n",
        "    out = tf.layers.Dense(h2,2)\n",
        "  return out"
      ],
      "metadata": {
        "id": "H018i_FLS4aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(X, hsize=[16,16], reuse=False):\n",
        "  with tf.variable_scope(\"GAN/Discriminator\", reuse=reuse):\n",
        "    h1 = tf.layers.Dense(X, hsize[0], activation=tf.nn.leaky_relu)\n",
        "    h2 = tf.layers.Dense(h1, hsize[1], activation=tf.nn.leaky_relu)\n",
        "    h3 = tf.layers.Dense(h2, 2)\n",
        "    out = tf.layers.Dense(h3,1)\n",
        "  return out, h3"
      ],
      "metadata": {
        "id": "kRpxuFzRTwPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial training\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 2])\n",
        "Z = tf.placeholder(tf.float32, [None, 2])"
      ],
      "metadata": {
        "id": "S1JeDS0fUeEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_sample = generator(Z)\n",
        "r_logits, r_rep = discriminator(X)\n",
        "f_logits, g_rep = discriminator(G_sample, reuse=True)"
      ],
      "metadata": {
        "id": "iiVMJhmdUrB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_loss = tf.reduce_mean(\n",
        "    tf.nn.sigmoid_cross_entropy_with_logits(logits=r_logits, labels=tf.one_like(r_logits)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits, labels=tf.zeros_like(f_logits))\n",
        "    )\n",
        "gen_loss = tf.reduce_mean(\n",
        "    tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits, labels=tf.ones_like(f_logits))\n",
        "    )"
      ],
      "metadata": {
        "id": "p3pASm4OU4AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"GAN/Generator\")\n",
        "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"GAN/Discriminator\")\n",
        "\n",
        "gen_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(gen_loss, var_list=gen_vars) # G train step\n",
        "disc_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(disc_loss, var_list=disc_vars) # D train step"
      ],
      "metadata": {
        "id": "CsTCV7IKV3D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100001):\n",
        "  X_batch = sample_data(n=batch_size)\n",
        "  Z_batch = sample_Z(batch_size, 2)\n",
        "  _, dloss = sess.run([disc_step, disc_loss], feed_dict={X:X_batch, Z: Z_batch})\n",
        "  _, gloss = sess_run([gen_step, gen_loss], feed_dict={Z: Z_batch})\n",
        "\n",
        "  print(\"Iterations : %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(i, dloss, gloss))"
      ],
      "metadata": {
        "id": "Rt0cIGsoV2yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}